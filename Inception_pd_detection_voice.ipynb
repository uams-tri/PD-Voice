{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception Model for Parkinson's Disease detection from voice spectral data.  \n",
    "# The Inception V3 model, pretrained on Imagenet is adapted using transfer learning to\n",
    "# extract features from spectrogram images of the sustained vowel /a/ to distinguish people \n",
    "# with Parkinsonâ€™s Disease (PwPD) from healthy controls (HC).  \n",
    "# \n",
    "# Audio files were preprocessed using the R packages Create_Liner(Mel)Spectrograms_(dataset) which are available in https://github.com/uams-tri/PD-Voice.\n",
    "# \n",
    "# Spectra files must be oranized into the directory structure required by the Keras ImageDatatGenerator() class when using the\n",
    "# class_mode- 'categorical' option as described in \n",
    "# https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720.\n",
    "# The pathname to this directory strucutre must be changed for each data set being analyzed. Output file names should be modified per experiment.\n",
    "# This approach was used to improve understandability.\n",
    "# For comparison with other analyses performeed on these data, training for transfer learing is re-initialized on each of 100 iterations retaining ROC data.\n",
    "\n",
    "\n",
    "# Copyright (C) 2024 University of Arkansas for Medical Sciences\n",
    "# Author: Anu Iyer, Fred Prior, PhD FWPrior@uams.edu\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "\n",
    "# You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e3b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import datetime\n",
    "import math\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa26b4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Start\n",
    "start = timeit.default_timer()\n",
    "data_path = '../../mPowerHiFreqData' # Change Pathname for each experiment \n",
    "img_rows = 600\n",
    "img_cols = 600\n",
    "batch_size = 4\n",
    "epochs = 10\n",
    "n_runs = 100 \n",
    "\n",
    "all_auc = []\n",
    "for run in range(n_runs):\n",
    "    print(\"run={}\".format(run))    \n",
    "    # Load data for each run. Remember to organize input data into the data structure described above so flow-from-directory() can identify labels.\n",
    "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                       fill_mode='nearest',\n",
    "                                       validation_split=0.3)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(data_path,\n",
    "                                                        target_size=(img_rows, img_cols),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=True)\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(data_path,\n",
    "                                                            target_size=(img_rows, img_cols),\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            class_mode='categorical',\n",
    "                                                            shuffle = False)\n",
    "\n",
    "    # load pre-trained InceptionV3 each time through the loop\n",
    "    pre_trained = InceptionV3(weights='imagenet', include_top=False, input_shape=(600,600,3), pooling='avg')\n",
    "    # Remove classifier and replace with a simple MLP\n",
    "    for layer in pre_trained.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = pre_trained.output\n",
    "    x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)   # Batch normalization was applied prior to the MLP classifier to minimize internal covariate shift \n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)  # applying batch normalization followed by dropout serves to pre-whiten the data, improving training performance \n",
    "\n",
    "    predictions = Dense(2, activation='sigmoid')(x) #softmax\n",
    "\n",
    "    model = Model(inputs = pre_trained.input, outputs = predictions)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer = Adam(learning_rate=0.001),\n",
    "                  metrics=['accuracy'],\n",
    "                 )\n",
    "\n",
    "    #Train, note: change the filepath name to match the experiment\n",
    "    newmodel=model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=validation_generator.samples // batch_size,\n",
    "                    callbacks=[\n",
    "                        tf.keras.callbacks.ModelCheckpoint(filepath = 'mPowerHiFreqData2model_{accuracy:.3f}.h5', save_best_only=True,\n",
    "                        save_weights_only=False, monitor='accuracy')\n",
    "                    ])\n",
    "                    \n",
    "        \n",
    "    Y_pred = model.predict(validation_generator, batch_size)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    # Generate ROC curve values: fpr, tpr, thresholds\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(validation_generator.classes, y_pred)\n",
    "    metrics.auc(fpr, tpr)\n",
    "    print(\"auc: {}\".format(round(metrics.auc(fpr, tpr), 2)))\n",
    "    all_auc.append(metrics.auc(fpr, tpr))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "        \n",
    "model.save(\"mPowerHiFreqData2Best.h5\")  # save the best model\n",
    "print(\"\\n\")\n",
    "#  Record Runtime\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('RunTime: ', round(stop - start, 2), 'Seconds')\n",
    "print(\"\\n\")\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict(validation_generator, batch_size)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report:')\n",
    "target_names = ['healthy', 'parkinson']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "print(\"avg auc: {} ({})\".format(np.round(np.average(all_auc), 4), np.round(np.std(all_auc), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00471c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot training data\n",
    "\n",
    "accs = newmodel.history['accuracy']\n",
    "val_accs = newmodel.history['val_accuracy']\n",
    "\n",
    "plt.plot(range(len(accs)),accs, label = 'Training_accuracy')\n",
    "plt.plot(range(len(accs)),val_accs, label = 'Validation_accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "accs = newmodel.history['loss']\n",
    "val_accs = newmodel.history['val_loss']\n",
    "\n",
    "plt.plot(range(len(accs)),accs, label = 'Training_loss')\n",
    "plt.plot(range(len(accs)),val_accs, label = 'Validation_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print and Store AUC vector\n",
    "\n",
    "print('AUC vector: ', all_auc)\n",
    "\n",
    "DF = pd.DataFrame(all_auc) # convert array into dataframe \n",
    "  \n",
    "DF.to_csv(\"mPowerHiFreqData2AUC.csv\") # save the dataframe as a csv file, be sure to change the file name to match the experiment\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
