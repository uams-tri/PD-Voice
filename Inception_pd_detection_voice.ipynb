{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d53279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception Model for Parkinson's Disease detection from voice spectral data.  \n",
    "# The Inception V3 model, pretrained on Imagenet is adapted using transfer learning to\n",
    "# extract features from spectrogram images of the sustained vowel /a/ to distinguish people \n",
    "# with Parkinsonâ€™s Disease (PwPD) and healthy controls (HC).  Audio files were preprocessed using\n",
    "# the R packages Create_Liner(Mel)Spectrograms_(dataset). \n",
    "# Spectra must be oranized into a directory structure as described in \n",
    "# https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
    "# The pathname to this directory strucutre must be changed for each data set being analyzed.\n",
    "# For comparison with other analyses performeed on these data, training for transfer learing is re-initialized on each of 100 iterations retaining ROC data.\n",
    "\n",
    "\n",
    "# Copyright (C) 2024 University of Arkansas for Medical Sciences\n",
    "# Author: Anu Iyer, Fred Prior, PhD FWPrior@uams.edu\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "\n",
    "# You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e3b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import datetime\n",
    "import math\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa26b4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Start\n",
    "start = timeit.default_timer()\n",
    "data_path = '../../mPowerHiFreqData' # Change Pathname for each experiment \n",
    "img_rows = 600\n",
    "img_cols = 600\n",
    "batch_size = 4\n",
    "epochs = 10\n",
    "n_runs = 100 \n",
    "\n",
    "all_auc = []\n",
    "for run in range(n_runs):\n",
    "    print(\"run={}\".format(run))    \n",
    "    # Load data for each run. \n",
    "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                       fill_mode='nearest',\n",
    "                                       validation_split=0.3)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(data_path,\n",
    "                                                        target_size=(img_rows, img_cols),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=True)\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(data_path,\n",
    "                                                            target_size=(img_rows, img_cols),\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            class_mode='categorical',\n",
    "                                                            shuffle = False)\n",
    "\n",
    "    # load pre-trained InceptionV3\n",
    "    pre_trained = InceptionV3(weights='imagenet', include_top=False, input_shape=(600,600,3), pooling='avg')\n",
    "    # Remove classifier and replace with a simple MLP\n",
    "    for layer in pre_trained.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = pre_trained.output\n",
    "    x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    predictions = Dense(2, activation='sigmoid')(x) #softmax for multiclass\n",
    "\n",
    "    model = Model(inputs = pre_trained.input, outputs = predictions)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer = Adam(learning_rate=0.001),\n",
    "                  metrics=['accuracy'],\n",
    "                 )\n",
    "\n",
    "    #Train\n",
    "    newmodel=model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=validation_generator.samples // batch_size,\n",
    "                    callbacks=[\n",
    "                        tf.keras.callbacks.ModelCheckpoint(filepath = 'mPowerHiFreqData2model_{accuracy:.3f}.h5', save_best_only=True,\n",
    "                        save_weights_only=False, monitor='accuracy')\n",
    "                    ])\n",
    "                    \n",
    "        \n",
    "    Y_pred = model.predict(validation_generator, batch_size)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    # Generate ROC curve values: fpr, tpr, thresholds\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(validation_generator.classes, y_pred)\n",
    "    metrics.auc(fpr, tpr)\n",
    "    print(\"auc: {}\".format(round(metrics.auc(fpr, tpr), 2)))\n",
    "    all_auc.append(metrics.auc(fpr, tpr))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "        \n",
    "model.save(\"mPowerHiFreqData2Best.h5\")\n",
    "print(\"\\n\")\n",
    "#  Record Runtime\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('RunTime: ', round(stop - start, 2), 'Seconds')\n",
    "print(\"\\n\")\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict(validation_generator, batch_size)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report:')\n",
    "target_names = ['healthy', 'parkinson']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "print(\"avg auc: {} ({})\".format(np.round(np.average(all_auc), 4), np.round(np.std(all_auc), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00471c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot training data\n",
    "\n",
    "accs = newmodel.history['accuracy']\n",
    "val_accs = newmodel.history['val_accuracy']\n",
    "\n",
    "plt.plot(range(len(accs)),accs, label = 'Training_accuracy')\n",
    "plt.plot(range(len(accs)),val_accs, label = 'Validation_accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "accs = newmodel.history['loss']\n",
    "val_accs = newmodel.history['val_loss']\n",
    "\n",
    "plt.plot(range(len(accs)),accs, label = 'Training_loss')\n",
    "plt.plot(range(len(accs)),val_accs, label = 'Validation_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print and Store AUC vector\n",
    "\n",
    "print('AUC vector: ', all_auc)\n",
    "\n",
    "DF = pd.DataFrame(all_auc) # convert array into dataframe \n",
    "  \n",
    "DF.to_csv(\"mPowerHiFreqData2AUC.csv\") # save the dataframe as a csv file \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
